{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw7UHT/MdRFVBpLrZuKCmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagoalmeida-TLM/hospedagem_geocode/blob/main/geocode_hospedagem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Latitude e longitude separado*"
      ],
      "metadata": {
        "id": "PNg7QTRy1JM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizado para buscar geolocalização de uma base de hospegadem que contém DATA, CHAPA, NOME, CIDADE.\n",
        "\n",
        "Arquivos: base_ativos.xlsx; hospedagem.xlsx; registro_ponto.xlsx (clockin)\n",
        "\n",
        "Foi cotejado com base do Clockin e Empregados Ativos.\n",
        "\n",
        "Resultado retorna todos os horários com sua geolocalização.\n",
        "\n",
        "Retorna Cidade e Estado.\n",
        "\n",
        "Aba Entrada: retorna horários em ordem crescente\n",
        "\n",
        "Aba Saída: retorna horários em ordem decrescente."
      ],
      "metadata": {
        "id": "aD5hKVHN4rkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Instalar dependências (se necessário)\n",
        "#!pip install openpyxl pandas geopy tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Configurar o tqdm para usar o método .progress_apply()\n",
        "tqdm.pandas()\n",
        "\n",
        "print(\"Iniciando o processamento de dados...\")\n",
        "\n",
        "# --- DICIONÁRIO E FUNÇÕES AUXILIARES ---\n",
        "\n",
        "ESTADOS_ABREVIADOS = {\n",
        "    'Acre': 'AC', 'Alagoas': 'AL', 'Amapá': 'AP', 'Amazonas': 'AM',\n",
        "    'Bahia': 'BA', 'Ceará': 'CE', 'Distrito Federal': 'DF', 'Espírito Santo': 'ES',\n",
        "    'Goiás': 'GO', 'Maranhão': 'MA', 'Mato Grosso': 'MT', 'Mato Grosso do Sul': 'MS',\n",
        "    'Minas Gerais': 'MG', 'Pará': 'PA', 'Paraíba': 'PB', 'Paraná': 'PR',\n",
        "    'Pernambuco': 'PE', 'Piauí': 'PI', 'Rio de Janeiro': 'RJ', 'Rio Grande do Norte': 'RN',\n",
        "    'Rio Grande do Sul': 'RS', 'Rondônia': 'RO', 'Roraima': 'RR', 'Santa Catarina': 'SC',\n",
        "    'São Paulo': 'SP', 'Sergipe': 'SE', 'Tocantins': 'TO'\n",
        "}\n",
        "\n",
        "def abreviar_estado(nome_estado):\n",
        "    if not nome_estado:\n",
        "        return None\n",
        "    nome_limpo = str(nome_estado).strip().title()\n",
        "    return ESTADOS_ABREVIADOS.get(nome_limpo, nome_estado)\n",
        "\n",
        "# Função para agregar HORA, LATITUDE e LONGITUDE juntos em colunas sequenciais\n",
        "def agregar_hora_lat_lon_juntos(df_ponto):\n",
        "    resultado = {}\n",
        "    for i, row in enumerate(df_ponto.itertuples(), start=1):\n",
        "        hora_str = row.HORA.strftime('%H:%M:%S') if hasattr(row.HORA, 'strftime') else None\n",
        "        resultado[f'HORA_{i}'] = hora_str\n",
        "        resultado[f'LATITUDE_{i}'] = row.LATITUDE\n",
        "        resultado[f'LONGITUDE_{i}'] = row.LONGITUDE\n",
        "    return pd.Series(resultado)\n",
        "\n",
        "# FUNÇÃO DE LIMPEZA COM CORREÇÃO DO SettingWithCopyWarning\n",
        "def limpar_base(df, status, cols_map):\n",
        "    # Usa .copy() explicitamente para evitar o SettingWithCopyWarning\n",
        "    df_limpo = df[[c for c in cols_map if c in df.columns]].copy()\n",
        "\n",
        "    df_limpo['CHAPA_LIMPA'] = df_limpo['CHAPA'].astype(str).str.strip()\n",
        "    df_limpo['CPF_LIMPO'] = df_limpo['CPF'].astype(str).str.strip()\n",
        "    df_limpo['DESCRICAO'] = df_limpo['DESCRICAO'].astype(str).str.strip()\n",
        "    df_limpo['STATUS'] = status\n",
        "    return df_limpo\n",
        "\n",
        "\n",
        "# --- FUNÇÕES DE BUSCA E ORDENAÇÃO (Mantidas) ---\n",
        "\n",
        "def buscar_pontos_entrada(row, ponto_validos):\n",
        "    chapa = row['CHAPA']\n",
        "    data = row['DATA']\n",
        "    pontos = ponto_validos[(ponto_validos['CHAPA'] == chapa) & (ponto_validos['DATA'] == data)]\n",
        "    if pontos.empty:\n",
        "        return pd.Series()\n",
        "    pontos_ordenados = pontos.sort_values(by='HORA', ascending=True)\n",
        "    return agregar_hora_lat_lon_juntos(pontos_ordenados)\n",
        "\n",
        "def buscar_pontos_saida(row, ponto_validos):\n",
        "    chapa = row['CHAPA']\n",
        "    data = row['DATA']\n",
        "    pontos = ponto_validos[(ponto_validos['CHAPA'] == chapa) & (ponto_validos['DATA'] == data)]\n",
        "    if pontos.empty:\n",
        "        return pd.Series()\n",
        "    pontos_ordenados = pontos.sort_values(by='HORA', ascending=False)\n",
        "    return agregar_hora_lat_lon_juntos(pontos_ordenados)\n",
        "\n",
        "def reorganizar_colunas(df, prefixos=['HORA', 'LATITUDE', 'LONGITUDE', 'LOCALIZACAO']):\n",
        "    colunas_originais = [col for col in df.columns if not any(col.startswith(p) for p in prefixos)]\n",
        "\n",
        "    indices = set()\n",
        "    for col in df.columns:\n",
        "        for p in prefixos:\n",
        "            if col.startswith(p + '_'):\n",
        "                try:\n",
        "                    idx = int(col.split('_')[1])\n",
        "                    indices.add(idx)\n",
        "                except:\n",
        "                    pass\n",
        "    indices = sorted(indices)\n",
        "\n",
        "    colunas_ordenadas = colunas_originais.copy()\n",
        "    for i in indices:\n",
        "        for p in prefixos:\n",
        "            colunas_ordenadas.append(f'{p}_{i}')\n",
        "\n",
        "    return df[colunas_ordenadas]\n",
        "\n",
        "\n",
        "# --- ETAPAS DE PROCESSAMENTO DE DADOS ---\n",
        "\n",
        "# 1. Leitura e Preparação das Bases (Ativos e Demitidos Combinadas)\n",
        "cols_map = {'CHAPA', 'CPF', 'DESCRICAO'}\n",
        "try:\n",
        "    base_ativos = pd.read_excel('base_ativos.xlsx')\n",
        "    base_demitidos = pd.read_excel('base_demitidos.xlsx')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"ERRO: Arquivo {e.filename} não encontrado.\")\n",
        "    exit()\n",
        "\n",
        "base_ativos_limpa = limpar_base(base_ativos, 'ATIVO', cols_map)\n",
        "base_demitidos_limpa = limpar_base(base_demitidos, 'DEMITIDO', cols_map)\n",
        "\n",
        "# Combina as bases, priorizando ATIVOS em caso de CHAPA duplicada\n",
        "base_completa = pd.concat([base_ativos_limpa, base_demitidos_limpa], ignore_index=True)\n",
        "base_completa = base_completa.drop_duplicates(subset=['CHAPA_LIMPA'], keep='first')\n",
        "\n",
        "# Criação dos dicionários de mapeamento a partir da base completa\n",
        "chapa_to_cpf = dict(zip(base_completa['CHAPA_LIMPA'], base_completa['CPF_LIMPO']))\n",
        "chapa_to_descricao = dict(zip(base_completa['CHAPA_LIMPA'], base_completa['DESCRICAO']))\n",
        "cpf_to_chapa = dict(zip(base_completa['CPF_LIMPO'], base_completa['CHAPA_LIMPA']))\n",
        "\n",
        "\n",
        "# 2. Leitura e Preparação da Hospedagem (Mapeamento CHAPA -> CPF e DESCRICAO)\n",
        "try:\n",
        "    hosp_entrada = pd.read_excel('hospedagem.xlsx', sheet_name='Entrada')\n",
        "    hosp_saida = pd.read_excel('hospedagem.xlsx', sheet_name='Saída')\n",
        "except FileNotFoundError:\n",
        "    print(\"ERRO: Arquivo 'hospedagem.xlsx' não encontrado.\")\n",
        "    exit()\n",
        "\n",
        "# Limpar CHAPA na Hospedagem\n",
        "hosp_entrada['CHAPA_LIMPA'] = hosp_entrada['CHAPA'].astype(str).str.strip()\n",
        "hosp_saida['CHAPA_LIMPA'] = hosp_saida['CHAPA'].astype(str).str.strip()\n",
        "\n",
        "# Adiciona CPF e DESCRICAO\n",
        "hosp_entrada['CPF'] = hosp_entrada['CHAPA_LIMPA'].map(chapa_to_cpf).fillna('Não Localizado')\n",
        "hosp_entrada['DESCRICAO'] = hosp_entrada['CHAPA_LIMPA'].map(chapa_to_descricao).fillna('Não Localizado')\n",
        "hosp_saida['CPF'] = hosp_saida['CHAPA_LIMPA'].map(chapa_to_cpf).fillna('Não Localizado')\n",
        "hosp_saida['DESCRICAO'] = hosp_saida['CHAPA_LIMPA'].map(chapa_to_descricao).fillna('Não Localizado')\n",
        "\n",
        "\n",
        "# Prepara as colunas originais\n",
        "hosp_entrada['DATA'] = pd.to_datetime(hosp_entrada['DATA']).dt.date\n",
        "hosp_saida['DATA'] = pd.to_datetime(hosp_saida['DATA']).dt.date\n",
        "hosp_entrada['CHAPA'] = hosp_entrada['CHAPA_LIMPA']\n",
        "hosp_saida['CHAPA'] = hosp_saida['CHAPA_LIMPA']\n",
        "hosp_entrada = hosp_entrada.drop(columns=['CHAPA_LIMPA'])\n",
        "hosp_saida = hosp_saida.drop(columns=['CHAPA_LIMPA'])\n",
        "\n",
        "\n",
        "# 3. Leitura e Preparação do Registro de Ponto (mdmpersonid -> CHAPA)\n",
        "try:\n",
        "    registro_ponto = pd.read_excel('registro_ponto.xlsx')\n",
        "except FileNotFoundError:\n",
        "    print(\"ERRO: Arquivo 'registro_ponto.xlsx' não encontrado.\")\n",
        "    exit()\n",
        "\n",
        "def extrair_data_hora_gmt(eventdatestr):\n",
        "    if pd.isna(eventdatestr): return None, None, None\n",
        "    try:\n",
        "        dt = datetime.fromisoformat(eventdatestr[:-6])\n",
        "        return dt.date(), dt.time(), eventdatestr[-6:]\n",
        "    except Exception: return None, None, None\n",
        "\n",
        "def extrair_lat_lon(coord_str):\n",
        "    if pd.isna(coord_str): return None, None\n",
        "    try:\n",
        "        coord = json.loads(str(coord_str).replace(\"'\", '\"'))\n",
        "        return coord.get('lat'), coord.get('lon')\n",
        "    except: return None, None\n",
        "\n",
        "registro_ponto[['DATA', 'HORA', 'GMT']] = registro_ponto['eventdatestr'].apply(\n",
        "    lambda x: pd.Series(extrair_data_hora_gmt(x))\n",
        ")\n",
        "registro_ponto[['LATITUDE', 'LONGITUDE']] = registro_ponto['coordinates'].apply(\n",
        "    lambda x: pd.Series(extrair_lat_lon(x))\n",
        ")\n",
        "\n",
        "registro_ponto['mdmpersonid_LIMPO'] = registro_ponto['mdmpersonid'].astype(str).str.strip()\n",
        "registro_ponto['CHAPA'] = registro_ponto['mdmpersonid_LIMPO'].map(cpf_to_chapa)\n",
        "registro_ponto['CHAPA'] = registro_ponto['CHAPA'].fillna('Não Localizado CPF')\n",
        "\n",
        "ponto_validos = registro_ponto[registro_ponto['CHAPA'] != 'Não Localizado CPF']\n",
        "\n",
        "\n",
        "# 4. Aplicação da Busca de Pontos com Ordenação\n",
        "print(\"\\nBuscando e ordenando pontos de registro por horário...\")\n",
        "dados_pontos_entrada = hosp_entrada.apply(lambda row: buscar_pontos_entrada(row, ponto_validos), axis=1)\n",
        "dados_pontos_saida = hosp_saida.apply(lambda row: buscar_pontos_saida(row, ponto_validos), axis=1)\n",
        "\n",
        "resultado_entrada = pd.concat([hosp_entrada, dados_pontos_entrada], axis=1)\n",
        "resultado_saida = pd.concat([hosp_saida, dados_pontos_saida], axis=1)\n",
        "\n",
        "\n",
        "# --- 5. GEOLOCALIZAÇÃO (Formatando como CIDADE/UF) ---\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"meu_app_geolocalizacao\", timeout=10)\n",
        "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
        "\n",
        "cache_coords = {}\n",
        "\n",
        "def obter_cidade_estado(lat, lon):\n",
        "    if pd.isna(lat) or pd.isna(lon): return None\n",
        "\n",
        "    chave = (round(lat, 5), round(lon, 5))\n",
        "    if chave in cache_coords: return cache_coords[chave]\n",
        "\n",
        "    try:\n",
        "        location = reverse(chave, language='pt', exactly_one=True)\n",
        "        if location and location.raw and 'address' in location.raw:\n",
        "            addr = location.raw['address']\n",
        "            cidade = addr.get('city') or addr.get('town') or addr.get('village') or addr.get('municipality')\n",
        "            estado_completo = addr.get('state')\n",
        "            estado_abreviado = abreviar_estado(estado_completo)\n",
        "\n",
        "            localizacao = f\"{cidade}/{estado_abreviado}\" if cidade and estado_abreviado else (cidade or estado_abreviado)\n",
        "\n",
        "            cache_coords[chave] = localizacao\n",
        "            return localizacao\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    cache_coords[chave] = None\n",
        "    return None\n",
        "\n",
        "def adicionar_cidade_estado(df, nome_aba):\n",
        "    max_pontos = 0\n",
        "    for col in df.columns:\n",
        "        if col.startswith('LATITUDE_'):\n",
        "            try: max_pontos = max(max_pontos, int(col.split('_')[1]))\n",
        "            except: pass\n",
        "\n",
        "    for i in range(1, max_pontos + 1):\n",
        "        lat_col, lon_col = f'LATITUDE_{i}', f'LONGITUDE_{i}'\n",
        "        localizacao_col = f'LOCALIZACAO_{i}'\n",
        "\n",
        "        if lat_col in df.columns and lon_col in df.columns:\n",
        "\n",
        "            df[localizacao_col] = None\n",
        "\n",
        "            indices_para_buscar = df[\n",
        "                (df[lat_col].notna()) & (df[lon_col].notna())\n",
        "            ].index\n",
        "\n",
        "            df_para_buscar = df.loc[indices_para_buscar].copy()\n",
        "\n",
        "            if not df_para_buscar.empty:\n",
        "                print(f\"\\nBuscando coordenadas (coluna {i}) para a aba '{nome_aba}' ({len(df_para_buscar)} pontos a buscar)...\")\n",
        "\n",
        "                resultados_busca = df_para_buscar.progress_apply(\n",
        "                    lambda row: obter_cidade_estado(row[lat_col], row[lon_col]), axis=1\n",
        "                )\n",
        "\n",
        "                df.loc[indices_para_buscar, localizacao_col] = resultados_busca\n",
        "            else:\n",
        "                 print(f\"\\nNenhum ponto válido encontrado na coluna {i} da aba '{nome_aba}'. Pulando busca.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Iniciando consulta Nominatim para LOCALIZAÇÃO (CIDADE/UF) com barra de progresso...\")\n",
        "print(\"Isto pode levar tempo devido ao limite de 1 segundo por consulta.\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "resultado_entrada = adicionar_cidade_estado(resultado_entrada, \"Entrada\")\n",
        "resultado_saida = adicionar_cidade_estado(resultado_saida, \"Saída\")\n",
        "\n",
        "print(\"\\nConsulta concluída.\")\n",
        "\n",
        "# Reorganizar colunas\n",
        "resultado_entrada = reorganizar_colunas(resultado_entrada)\n",
        "resultado_saida = reorganizar_colunas(resultado_saida)\n",
        "\n",
        "# --- 6. Exportar resultados ---\n",
        "print(\"\\nExportando resultados para o arquivo Excel...\")\n",
        "with pd.ExcelWriter('resultado_hospedagem_com_pontos_localizacao.xlsx', engine='openpyxl') as writer:\n",
        "    resultado_entrada.to_excel(writer, sheet_name='Entrada', index=False)\n",
        "    resultado_saida.to_excel(writer, sheet_name='Saída', index=False)\n",
        "\n",
        "print(\"\\nProcessamento concluído.\")\n",
        "print(\"Arquivo gerado: resultado_hospedagem_com_pontos_localizacao.xlsx com abas 'Entrada' e 'Saída'.\")"
      ],
      "metadata": {
        "id": "GHNOlmxgEIMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Iniciando teste de mapeamento completo (Ativos + Demitidos)...\")\n",
        "\n",
        "# --- 1. Leitura e Preparação das Bases (Ativos e Demitidos Combinadas) ---\n",
        "try:\n",
        "    # Leitura das bases\n",
        "    base_ativos = pd.read_excel('base_ativos.xlsx')\n",
        "    base_demitidos = pd.read_excel('base_demitidos.xlsx')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"ERRO: Arquivo {e.filename} não encontrado. Verifique o nome do arquivo.\")\n",
        "    exit()\n",
        "\n",
        "cols_map = {'CHAPA', 'CPF', 'DESCRICAO'}\n",
        "\n",
        "# Função auxiliar para limpar e padronizar\n",
        "def limpar_base(df, status):\n",
        "    df_limpo = df[[c for c in cols_map if c in df.columns]]\n",
        "    df_limpo['CHAPA_LIMPA'] = df_limpo['CHAPA'].astype(str).str.strip()\n",
        "    df_limpo['CPF_LIMPO'] = df_limpo['CPF'].astype(str).str.strip()\n",
        "    df_limpo['DESCRICAO'] = df_limpo['DESCRICAO'].astype(str).str.strip()\n",
        "    df_limpo['STATUS'] = status\n",
        "    return df_limpo[['CHAPA_LIMPA', 'CPF_LIMPO', 'DESCRICAO', 'STATUS']]\n",
        "\n",
        "base_ativos_limpa = limpar_base(base_ativos, 'ATIVO')\n",
        "base_demitidos_limpa = limpar_base(base_demitidos, 'DEMITIDO')\n",
        "\n",
        "# Combina as bases, priorizando ATIVOS em caso de CHAPA duplicada\n",
        "base_completa = pd.concat([base_ativos_limpa, base_demitidos_limpa], ignore_index=True)\n",
        "base_completa = base_completa.drop_duplicates(subset=['CHAPA_LIMPA'], keep='first')\n",
        "\n",
        "# Dicionário CHAPA -> CPF\n",
        "chapa_to_cpf = dict(zip(base_completa['CHAPA_LIMPA'], base_completa['CPF_LIMPO']))\n",
        "\n",
        "print(f\"Base Completa (Ativos + Demitidos) carregada. Total de {len(base_completa)} registros únicos (CHAPA).\")\n",
        "\n",
        "\n",
        "# --- 2. Leitura e Preparação da Hospedagem ---\n",
        "try:\n",
        "    hosp_entrada = pd.read_excel('hospedagem.xlsx', sheet_name='Entrada')\n",
        "    hosp_saida = pd.read_excel('hospedagem.xlsx', sheet_name='Saída')\n",
        "except FileNotFoundError:\n",
        "    print(\"ERRO: Arquivo 'hospedagem.xlsx' não encontrado.\")\n",
        "    exit()\n",
        "\n",
        "# Limpar CHAPA na Hospedagem\n",
        "hosp_entrada['CHAPA_LIMPA'] = hosp_entrada['CHAPA'].astype(str).str.strip()\n",
        "hosp_saida['CHAPA_LIMPA'] = hosp_saida['CHAPA'].astype(str).str.strip()\n",
        "\n",
        "\n",
        "# --- 3. Mapeamento e Análise ---\n",
        "\n",
        "def analisar_resultados(df, nome_aba):\n",
        "    # Tenta mapear o CPF usando a CHAPA limpa da base completa\n",
        "    df['CPF_ENCONTRADO'] = df['CHAPA_LIMPA'].map(chapa_to_cpf)\n",
        "\n",
        "    # Conta quantos CPFs foram encontrados (não são NaN)\n",
        "    encontrados = df['CPF_ENCONTRADO'].notna().sum()\n",
        "    nao_encontrados = df['CPF_ENCONTRADO'].isna().sum()\n",
        "    total = len(df)\n",
        "\n",
        "    print(f\"\\n--- Resultado para a aba '{nome_aba}' ---\")\n",
        "    print(f\"Total de registros: {total}\")\n",
        "    print(f\"CPF/CHAPA encontrado(s): {encontrados}\")\n",
        "    print(f\"CPF/CHAPA NÃO encontrado(s): {nao_encontrados}\")\n",
        "\n",
        "    if nao_encontrados > 0:\n",
        "        # Exibe as CHAPAS que falharam\n",
        "        chapas_falharam = df[df['CPF_ENCONTRADO'].isna()]['CHAPA_LIMPA'].unique()\n",
        "        print(f\"\\nCHAPAs únicas que AINDA falharam no mapeamento:\")\n",
        "        # Limita a exibição a 10 para não sobrecarregar\n",
        "        print(chapas_falharam[:10].tolist())\n",
        "\n",
        "    return nao_encontrados\n",
        "\n",
        "falhas_entrada = analisar_resultados(hosp_entrada, 'Entrada')\n",
        "falhas_saida = analisar_resultados(hosp_saida, 'Saída')\n",
        "\n",
        "print(\"\\nTeste de mapeamento concluído.\")\n",
        "\n",
        "if falhas_entrada == 0 and falhas_saida == 0:\n",
        "    print(\"\\n✅ SUCESSO! Todos os registros de hospedagem foram mapeados para um CPF/DESCRICAO na base combinada.\")\n",
        "    print(\"Você pode prosseguir com a execução do código completo.\")\n",
        "else:\n",
        "    print(\"\\n⚠️ ATENÇÃO: Ainda há registros que não puderam ser mapeados.\")\n",
        "    print(\"Isso geralmente indica que a CHAPA não existe em NENHUMA das bases (ativos ou demitidos), ou que o nome do campo nas bases originais está incorreto.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "96n_2n0jPO9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}